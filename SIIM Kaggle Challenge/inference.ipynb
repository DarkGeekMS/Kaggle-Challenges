{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.torch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode(rle, height=1024, width=1024, fill_value=1):\n",
    "    component = np.zeros((height, width), np.float32)\n",
    "    component = component.reshape(-1)\n",
    "    rle = np.array([int(s) for s in rle.strip().split(' ')])\n",
    "    rle = rle.reshape(-1, 2)\n",
    "    start = 0\n",
    "    for index, length in rle:\n",
    "        start = start+index\n",
    "        end = start+length\n",
    "        component[start: end] = fill_value\n",
    "        start = end\n",
    "    component = component.reshape(width, height).T\n",
    "    return component\n",
    "\n",
    "def run_length_encode(component):\n",
    "    component = component.T.flatten()\n",
    "    start = np.where(component[1:] > component[:-1])[0]+1\n",
    "    end = np.where(component[:-1] > component[1:])[0]+1\n",
    "    length = end-start\n",
    "    rle = []\n",
    "    for i in range(len(length)):\n",
    "        if i == 0:\n",
    "            rle.extend([start[0], length[0]])\n",
    "        else:\n",
    "            rle.extend([start[i]-end[i-1], length[i]])\n",
    "    rle = ' '.join([str(r) for r in rle])\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_folder = \"test2_png\"\n",
    "sample_submission_path = \"stage_2_sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root, df, size, mean, std, tta=4):\n",
    "        self.root = root\n",
    "        self.size = size\n",
    "        self.fnames = list(df[\"ImageId\"])\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.transform = Compose(\n",
    "            [\n",
    "                Normalize(mean=mean, std=std, p=1),\n",
    "                Resize(size, size),\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname + \".png\")\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "def post_process(probability, threshold, min_size):\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((1024, 1024), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dc324340914bf5af40755c9bcbb402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "size = 768\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "num_workers = 8\n",
    "batch_size = 1\n",
    "best_threshold = 0.6\n",
    "min_size = 3500\n",
    "device = torch.device(\"cuda:0\")\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, size, mean, std),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "model1 = smp.FPN(\"resnet34\", encoder_weights=\"imagenet\", activation=None).to(torch.device(\"cuda:0\"))\n",
    "model1.eval()\n",
    "state1 = torch.load('./stage2_models/resnet34_fpn.pth', map_location=lambda storage, loc: storage)\n",
    "model1.load_state_dict(state1[\"state_dict\"])\n",
    "model2 = smp.FPN(\"se_resnet50\", encoder_weights=\"imagenet\", activation=None).to(torch.device(\"cuda:0\"))\n",
    "model2.eval()\n",
    "state2 = torch.load('./stage2_models/se_resnet_fpn.pth', map_location=lambda storage, loc: storage)\n",
    "model2.load_state_dict(state2[\"state_dict\"])\n",
    "encoded_pixels = []\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "    preds1 = torch.sigmoid(model1(batch.to(device)))\n",
    "    preds1 = preds1.detach().cpu().numpy()[:, 0, :, :] \n",
    "    preds2 = torch.sigmoid(model2(batch.to(device)))\n",
    "    preds2 = preds2.detach().cpu().numpy()[:, 0, :, :] \n",
    "    for i in range(len(preds1)):\n",
    "        probability1 = preds1[i]\n",
    "        probability2 = preds2[i]\n",
    "        probability = (probability1+probability2) / 2.0\n",
    "        if probability.shape != (1024, 1024):\n",
    "            probability = cv2.resize(probability, dsize=(1024, 1024), interpolation=cv2.INTER_LINEAR)\n",
    "        predict, num_predict = post_process(probability, best_threshold, min_size)\n",
    "        if num_predict == 0:\n",
    "            encoded_pixels.append('-1')\n",
    "        else:\n",
    "            r = run_length_encode(predict)\n",
    "            encoded_pixels.append(r)\n",
    "df['EncodedPixels'] = encoded_pixels\n",
    "df.to_csv('submission.csv', columns=['ImageId', 'EncodedPixels'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0011fe81e</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_9ca06e9b9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_6f00d6ce6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_9258110b0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_fa01c9546</td>\n",
       "      <td>298289 8 1007 19 1000 25 38 20 937 31 27 33 92...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageId                                      EncodedPixels\n",
       "0  ID_0011fe81e                                                 -1\n",
       "1  ID_9ca06e9b9                                                 -1\n",
       "2  ID_6f00d6ce6                                                 -1\n",
       "3  ID_9258110b0                                                 -1\n",
       "4  ID_fa01c9546  298289 8 1007 19 1000 25 38 20 937 31 27 33 92..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
