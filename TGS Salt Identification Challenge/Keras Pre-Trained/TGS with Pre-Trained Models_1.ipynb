{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from segmentation_models import Unet\n",
    "\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input , Concatenate\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import *\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "im_chan = 3\n",
    "n_features = 1 \n",
    "path_train = 'data/train/'\n",
    "path_test = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img('data/train/images/' + img_name + '.png')\n",
    "    img_mask = load_img('data/train/masks/' + img_name + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), 256, 256 , 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "sum_whites = 0\n",
    "for n, id_ in enumerate(train_ids):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (256, 256 , 3), preserve_range=True)\n",
    "    X_train[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_train[n] = resize(mask, (256, 256, 1), preserve_range=True)\n",
    "    sum_whites += np.sum(Y_train[n])\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print(\"Salt in the dataset is {}\".format(sum_whites*1.0 / (X_train.shape[0] * 256*256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(X_train[ix])\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_val , Y_train , Y_val = train_test_split(X_train , Y_train , train_size = 0.9 , random_state = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2\n",
    ")\n",
    "\n",
    "mask_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2\n",
    ")\n",
    "\n",
    "val_image_generator = ImageDataGenerator(\n",
    ")\n",
    "val_mask_generator = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "train_img_gen = image_generator.flow(X_train , seed = 2021 , batch_size = 16)\n",
    "train_mask_gen = mask_generator.flow(Y_train , seed = 2021 , batch_size = 16)\n",
    "\n",
    "val_img_gen = val_image_generator.flow(X_val , seed = 2021 , batch_size = 16)\n",
    "val_mask_gen = val_mask_generator.flow(Y_val , seed = 2021 , batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = zip(train_img_gen , train_mask_gen)\n",
    "val_gen = zip(val_img_gen , val_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(backbone_name='resnet34' , input_shape = (256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dice_coef(y_true, y_pred):\n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred = K.cast(y_pred, 'float32')\n",
    "#     y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "#     intersection = y_true_f * y_pred_f\n",
    "#     score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "#     return score\n",
    "\n",
    "# def dice_loss(y_true, y_pred):\n",
    "#     smooth = 1.\n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred_f = K.flatten(y_pred)\n",
    "#     intersection = y_true_f * y_pred_f\n",
    "#     score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "#     return 1. - score\n",
    "\n",
    "# def bce_dice_loss(y_true, y_pred):\n",
    "#     return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "# def bce_logdice_loss(y_true, y_pred):\n",
    "#     return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "# def weighted_bce_loss(y_true, y_pred, weight):\n",
    "#     epsilon = 1e-7\n",
    "#     y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "#     logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "#     loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "#                      K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "#     return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "# def weighted_dice_loss(y_true, y_pred, weight):\n",
    "#     smooth = 1.\n",
    "#     w, m1, m2 = weight, y_true, y_pred\n",
    "#     intersection = (m1 * m2)\n",
    "#     score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "#     loss = 1. - K.sum(score)\n",
    "#     return loss\n",
    "\n",
    "# def weighted_bce_dice_loss(y_true, y_pred):\n",
    "#     y_true = K.cast(y_true, 'float32')\n",
    "#     y_pred = K.cast(y_pred, 'float32')\n",
    "#     # if we want to get same size of output, kernel size must be odd\n",
    "#     averaged_mask = K.pool2d(\n",
    "#             y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "#     weight = K.ones_like(averaged_mask)\n",
    "#     w0 = K.sum(weight)\n",
    "#     weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "#     w1 = K.sum(weight)\n",
    "#     weight *= (w0 / w1)\n",
    "#     loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "#     return loss\n",
    "  \n",
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [mean_iou , 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor = 'val_mean_iou' , factor = 0.5 , \n",
    "                               mode = 'max' , patience = 5 , verbose = 2 , min_delta = 0.01)\n",
    "checkpointer = ModelCheckpoint('resnet34_unet_2021.h5', monitor='val_mean_iou', \n",
    "                               verbose=2, save_best_only=True , save_weights_only = False , mode = 'max')\n",
    "early_stopper = EarlyStopping(monitor = 'val_mean_iou' , mode = 'max' , patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.fit_generator(train_gen , steps_per_epoch = 1125 , epochs = 200 ,\n",
    "                              validation_data = val_gen , validation_steps = 25 ,\n",
    "                              callbacks=[checkpointer , lr_reducer, early_stopper] , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (256, 256, 3) , preserve_range=True)\n",
    "    X_test[n] = x\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"resnet34_unet_2021.h5\" , custom_objects = {'mean_iou' : mean_iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = model.predict(X_val, verbose=1 , batch_size = 2)\n",
    "preds_test = model.predict(X_test , verbose = 1 , batch_size = 2)\n",
    "\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val , Y_val , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (101, 101), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    \n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "    \n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = np.linspace(0.25, 0.75, 20)\n",
    "thres_ioc = [iou_metric_batch(Y_val, np.int32(preds_val > t)) for t in thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thres, thres_ioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thres = thres[np.argmax(thres_ioc)]\n",
    "best_thres, max(thres_ioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i] > best_thres)) for i,fn in enumerate(test_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
