{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models.utils import set_trainable\n",
    "\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input , Concatenate\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import *\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "im_chan = 3\n",
    "n_features = 1 \n",
    "path_train = 'data/train/'\n",
    "path_test = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img('data/train/images/' + img_name + '.png')\n",
    "    img_mask = load_img('data/train/masks/' + img_name + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), 256, 256 , 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "sum_whites = 0\n",
    "for n, id_ in enumerate(train_ids):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (256, 256 , 3), preserve_range=True)\n",
    "    X_train[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_train[n] = resize(mask, (256, 256, 1), preserve_range=True)\n",
    "    sum_whites += np.sum(Y_train[n])\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print(\"Salt in the dataset is {}\".format(sum_whites*1.0 / (X_train.shape[0] * 256*256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(X_train[ix])\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(KFold(n_splits=3, shuffle=True, random_state=3001).split(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2\n",
    ")\n",
    "\n",
    "mask_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2\n",
    ")\n",
    "\n",
    "val_image_generator = ImageDataGenerator(\n",
    ")\n",
    "val_mask_generator = ImageDataGenerator(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "# def lovasz_grad(gt_sorted):\n",
    "#     \"\"\"\n",
    "#     Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "#     See Alg. 1 in paper\n",
    "#     \"\"\"\n",
    "#     gts = tf.reduce_sum(gt_sorted)\n",
    "#     intersection = gts - tf.cumsum(gt_sorted)\n",
    "#     union = gts + tf.cumsum(1. - gt_sorted)\n",
    "#     jaccard = 1. - intersection / union\n",
    "#     jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "#     return jaccard\n",
    "\n",
    "\n",
    "# # --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "# def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "#     \"\"\"\n",
    "#     Binary Lovasz hinge loss\n",
    "#       logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "#       labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "#       per_image: compute the loss per image instead of per batch\n",
    "#       ignore: void class id\n",
    "#     \"\"\"\n",
    "#     if per_image:\n",
    "#         def treat_image(log_lab):\n",
    "#             log, lab = log_lab\n",
    "#             log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "#             log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "#             return lovasz_hinge_flat(log, lab)\n",
    "#         losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "#         loss = tf.reduce_mean(losses)\n",
    "#     else:\n",
    "#         loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# def lovasz_hinge_flat(logits, labels):\n",
    "#     \"\"\"\n",
    "#     Binary Lovasz hinge loss\n",
    "#       logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "#       labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "#       ignore: label to ignore\n",
    "#     \"\"\"\n",
    "\n",
    "#     def compute_loss():\n",
    "#         labelsf = tf.cast(labels, logits.dtype)\n",
    "#         signs = 2. * labelsf - 1.\n",
    "#         errors = 1. - logits * tf.stop_gradient(signs)\n",
    "#         errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "#         gt_sorted = tf.gather(labelsf, perm)\n",
    "#         grad = lovasz_grad(gt_sorted)\n",
    "#         loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "#         return loss\n",
    "\n",
    "#     # deal with the void prediction case (only void pixels)\n",
    "#     loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "#                    lambda: tf.reduce_sum(logits) * 0.,\n",
    "#                    compute_loss,\n",
    "#                    strict=True,\n",
    "#                    name=\"loss\"\n",
    "#                    )\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# def flatten_binary_scores(scores, labels, ignore=None):\n",
    "#     \"\"\"\n",
    "#     Flattens predictions in the batch (binary case)\n",
    "#     Remove labels equal to 'ignore'\n",
    "#     \"\"\"\n",
    "#     scores = tf.reshape(scores, (-1,))\n",
    "#     labels = tf.reshape(labels, (-1,))\n",
    "#     if ignore is None:\n",
    "#         return scores, labels\n",
    "#     valid = tf.not_equal(labels, ignore)\n",
    "#     vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "#     vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "#     return vscores, vlabels\n",
    "\n",
    "# def lovasz_loss(y_true, y_pred):\n",
    "#     y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "#     #logits = K.log(y_pred / (1. - y_pred))\n",
    "#     logits = y_pred #Jiaxin\n",
    "#     loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(backbone_name='inceptionresnetv2', input_shape = (256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_callbacks(saver_name):\n",
    "        \n",
    "    lr_reducer = ReduceLROnPlateau(monitor = 'val_mean_iou' , factor = 0.5 , \n",
    "                                   mode = 'max' , patience = 5 , verbose = 2 , min_delta = 0.01)\n",
    "    checkpointer = ModelCheckpoint(saver_name, monitor='val_mean_iou', \n",
    "                                   verbose=2, save_best_only=True , save_weights_only = False , mode = 'max')\n",
    "    early_stopper = EarlyStopping(monitor = 'val_mean_iou' , mode = 'max' , patience = 10)\n",
    "    \n",
    "    return lr_reducer, checkpointer, early_stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j+1)\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    Y_train_cv = Y_train[train_idx]\n",
    "    X_valid_cv = X_train[val_idx]\n",
    "    Y_valid_cv= Y_train[val_idx]\n",
    "    \n",
    "    fold_name = \"inceptionresnetv2_unet_3001_fold\" + str(j+1) + \".h5\"\n",
    "    lr_reducer, checkpointer, early_stopper = get_callbacks(saver_name = fold_name)\n",
    "    \n",
    "    train_img_gen = image_generator.flow(X_train_cv , seed = 3001 , batch_size = 16)\n",
    "    train_mask_gen = mask_generator.flow(Y_train_cv , seed = 3001 , batch_size = 16)\n",
    "\n",
    "    val_img_gen = val_image_generator.flow(X_valid_cv  , seed = 3001 , batch_size = 16)\n",
    "    val_mask_gen = val_mask_generator.flow(Y_valid_cv , seed = 3001 , batch_size = 16)\n",
    "    \n",
    "    train_gen = zip(train_img_gen , train_mask_gen)\n",
    "    val_gen = zip(val_img_gen , val_mask_gen)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=1e-4) , loss = 'binary_crossentropy' , metrics = [mean_iou , 'acc'])\n",
    "    \n",
    "    model.fit_generator(train_gen, steps_per_epoch = 1125, epochs = 100, validation_data = val_gen, validation_steps = 25,\n",
    "                              callbacks=[checkpointer , lr_reducer, early_stopper], verbose = 1)\n",
    "    \n",
    "    print(model.evaluate(X_valid_cv, Y_valid_cv ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (256, 256, 3) , preserve_range=True)\n",
    "    X_test[n] = x\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"inceptionresnetv2_unet_3001_fold2.h5\" , custom_objects = {'mean_iou' : mean_iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model, x_test, img_size_target):\n",
    "    \n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    \n",
    "    preds_test += np.array([ np.fliplr(a) for a in \n",
    "                            model.predict(np.array([np.fliplr(x) \n",
    "                            for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    \n",
    "    preds_test += np.array([ np.flipud(a) for a in \n",
    "                            model.predict(np.array([np.flipud(x) \n",
    "                            for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    \n",
    "    preds_test += np.array([ np.fliplr(np.flipud(a)) for a in \n",
    "                            model.predict(np.array([np.fliplr(np.flipud(x)) \n",
    "                            for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    \n",
    "    return preds_test/4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = predict_result(model, X_val, 256)\n",
    "preds_test = predict_result(model, X_test, 256)\n",
    "\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val , Y_val , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (101, 101), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    \n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "    \n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = np.linspace(0.25, 0.75, 20)\n",
    "thres_ioc = [iou_metric_batch(Y_val, np.int32(preds_val > t)) for t in thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thres, thres_ioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thres = thres[np.argmax(thres_ioc)]\n",
    "best_thres, max(thres_ioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i] > best_thres)) for i,fn in enumerate(test_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
