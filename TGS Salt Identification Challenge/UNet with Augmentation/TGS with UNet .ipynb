{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input , Concatenate\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import *\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5\n",
    "im_chan = 3\n",
    "n_features = 1 \n",
    "path_train = 'data/train/'\n",
    "path_test = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "sum_whites = 0\n",
    "for n, id_ in enumerate(train_ids):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,:]\n",
    "    x = resize(x, (im_height, im_width, im_chan), mode='constant', preserve_range=True)\n",
    "    X_train[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,:]\n",
    "    Y_train[n] = resize(mask, (im_height, im_width, 1), mode='constant', preserve_range=True)\n",
    "    sum_whites += np.sum(Y_train[n])\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print(\"Salt in the dataset is {}\".format(sum_whites*1.0 / (X_train.shape[0] * 128*128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(X_train[ix])\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_val , Y_train , Y_val = train_test_split(X_train , Y_train , train_size = 0.9 , random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2\n",
    ")\n",
    "\n",
    "mask_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2\n",
    ")\n",
    "\n",
    "val_image_generator = ImageDataGenerator(\n",
    ")\n",
    "val_mask_generator = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "train_img_gen = image_generator.flow(X_train , seed = 2018 , batch_size = 16)\n",
    "train_mask_gen = mask_generator.flow(Y_train , seed = 2018 , batch_size = 16)\n",
    "\n",
    "val_img_gen = val_image_generator.flow(X_val , seed = 2018 , batch_size = 16)\n",
    "val_mask_gen = val_mask_generator.flow(Y_val , seed = 2018 , batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = zip(train_img_gen , train_mask_gen)\n",
    "val_gen = zip(val_img_gen , val_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, im_chan), name='img')\n",
    "\n",
    "inp = BatchNormalization()(input_img) \n",
    "\n",
    "c1 = Conv2D(4, (3, 3), activation='relu', padding='same') (inp)\n",
    "a1 = MaxPooling2D((2, 2))(c1)\n",
    "c1 = Dropout(0.2)(c1)\n",
    "c1 = Conv2D(4, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "cat1 = concatenate([p1, a1])\n",
    "\n",
    "c2 = Conv2D(8, (3, 3), activation='relu', padding='same') (cat1)\n",
    "a2 = MaxPooling2D((2, 2))(c2)\n",
    "c2 = Dropout(0.2)(c2)\n",
    "c2 = Conv2D(8, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "cat2 = concatenate([p2, a2])\n",
    "\n",
    "c3 = Conv2D(16, (3, 3), activation='relu', padding='same') (cat2)\n",
    "a3 = MaxPooling2D((2, 2))(c3)\n",
    "c3 = Dropout(0.2)(c3)\n",
    "c3 = Conv2D(16, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "cat3 = concatenate([p3, a3])\n",
    "\n",
    "c4 = Conv2D(32, (3, 3), activation='relu', padding='same') (cat3)\n",
    "a4 = MaxPooling2D((2, 2))(c4)\n",
    "c4 = Dropout(0.2)(c4)\n",
    "c4 = Conv2D(32, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D((2, 2)) (c4)\n",
    "\n",
    "cat4 = concatenate([p4, a4])\n",
    "\n",
    "c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (cat4)\n",
    "a5 = MaxPooling2D((2, 2))(c5)\n",
    "c5 = Dropout(0.2)(c5)\n",
    "c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n",
    "p5 = MaxPooling2D((2, 2)) (c5)\n",
    "\n",
    "cat5 = concatenate([p5, a5])\n",
    "\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', padding='same') (cat5)\n",
    "c6 = Dropout(0.2)(c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c5])\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Dropout(0.2)(c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c4])\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Dropout(0.2)(c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c3])\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Dropout(0.2)(c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "u10 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c9)\n",
    "u10 = concatenate([u10, c2])\n",
    "c10 = Conv2D(8, (3, 3), activation='relu', padding='same') (u10)\n",
    "c10 = Dropout(0.2)(c10)\n",
    "c10 = Conv2D(8, (3, 3), activation='relu', padding='same') (c10)\n",
    "\n",
    "u11 = Conv2DTranspose(4, (2, 2), strides=(2, 2), padding='same') (c10)\n",
    "u11 = concatenate([u11, c1], axis = 3)\n",
    "c11 = Conv2D(4, (3, 3), activation='relu', padding='same') (u11)\n",
    "c11 = Dropout(0.2)(c11)\n",
    "c11 = Conv2D(4, (3, 3), activation='relu', padding='same') (c11)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c11)\n",
    "\n",
    "model = Model(inputs=[input_img], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou]) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(monitor= 'val_mean_iou', patience=10, mode='max')\n",
    "lr_reducer = ReduceLROnPlateau(monitor= 'val_loss', factor=0.1, patience=5,  min_lr=1e-6, mode='max')\n",
    "checkpointer = ModelCheckpoint('unet_model.h5', monitor='val_mean_iou', verbose=2, save_best_only=True , mode = 'max')\n",
    "\n",
    "results = model.fit_generator(train_gen , steps_per_epoch = 1125 , epochs = 200,\n",
    "                              validation_data = val_gen , validation_steps = 25 ,\n",
    "                              callbacks=[checkpointer , lr_reducer, early_stopper] , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,:]\n",
    "    sizes_test.append([x.shape[0], x.shape[1]])\n",
    "    x = resize(x, (im_height, im_width, im_chan), mode='constant', preserve_range=True)\n",
    "    X_test[n] = x\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('unet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict(X_train, verbose=1)\n",
    "preds_val = model.predict(X_valid, verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled = []\n",
    "for i in tnrange(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds):\n",
    "    ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Seismic')\n",
    "\n",
    "    ax[1].imshow(X[ix, ..., 1], cmap='seismic')\n",
    "    if has_mask:\n",
    "        ax[1].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[1].set_title('Seismic cumsum')\n",
    "\n",
    "    ax[2].imshow(y[ix].squeeze())\n",
    "    ax[2].set_title('Salt')\n",
    "\n",
    "    ax[3].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[3].set_title('Salt Pred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_train, y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_valid, y_valid, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    \n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "    \n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = np.linspace(0.25, 0.75, 20)\n",
    "thres_ioc = [iou_metric_batch(y_valid, np.int32(preds_val > t)) for t in tqdm_notebook(thres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thres, thres_ioc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thres = thres[np.argmax(thres_ioc)]\n",
    "best_thres, max(thres_ioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "pred_dict = {id_[:-4]:RLenc(np.round(preds_test_upsampled[i] > best_thres)) for i,id_ in tqdm_notebook(enumerate(test_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('outputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
