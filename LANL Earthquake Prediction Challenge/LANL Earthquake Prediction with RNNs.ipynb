{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"LANL Earthquake Prediction/train.csv\", nrows=10000000)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename({\"acoustic_data\": \"signal\", \"time_to_failure\": \"quaketime\"}, axis=\"columns\", inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(20,12))\n",
    "ax[0].plot(train.index.values, train.quaketime.values)\n",
    "ax[0].set_title(\"Quaketime of 10 Mio rows\")\n",
    "ax[0].set_xlabel(\"Index\")\n",
    "ax[0].set_ylabel(\"Quaketime in ms\");\n",
    "ax[1].plot(train.index.values, train.signal.values, c=\"green\")\n",
    "ax[1].set_title(\"Signal of 10 Mio rows\")\n",
    "ax[1].set_xlabel(\"Index\")\n",
    "ax[1].set_ylabel(\"Acoustic Signal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = os.listdir(\"LANL Earthquake Prediction/test\")\n",
    "print(test_files[0:5])\n",
    "\n",
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"LANL Earthquake Prediction/sample_submission.csv\")\n",
    "print (sample_submission.head())\n",
    "len(sample_submission.seg_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1, figsize=(20,25))\n",
    "\n",
    "for n in range(4):\n",
    "    seg = pd.read_csv(\"LANL Earthquake Prediction/test/\"  + test_files[n])\n",
    "    ax[n].plot(seg.acoustic_data.values, c=\"mediumseagreen\")\n",
    "    ax[n].set_xlabel(\"Index\")\n",
    "    ax[n].set_ylabel(\"Signal\")\n",
    "    ax[n].set_ylim([-300, 300])\n",
    "    ax[n].set_title(\"Test {}\".format(test_files[n]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsize = np.diff(train.quaketime)\n",
    "train = train.drop(train.index[len(train)-1])\n",
    "train[\"stepsize\"] = stepsize\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.stepsize = train.stepsize.apply(lambda l: np.round(l, 10))\n",
    "stepsize_counts = train.stepsize.value_counts()\n",
    "stepsize_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [10, 50, 100, 1000]\n",
    "for window in window_sizes:\n",
    "    train[\"rolling_mean_\" + str(window)] = train.signal.rolling(window=window).mean()\n",
    "    train[\"rolling_std_\" + str(window)] = train.signal.rolling(window=window).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(window_sizes),1,figsize=(20,6*len(window_sizes)))\n",
    "\n",
    "n = 0\n",
    "for col in train.columns.values:\n",
    "    if \"rolling_\" in col:\n",
    "        if \"mean\" in col:\n",
    "            mean_df = train.iloc[4435000:4445000][col]\n",
    "            ax[n].plot(mean_df, label=col, color=\"mediumseagreen\")\n",
    "        if \"std\" in col:\n",
    "            std = train.iloc[4435000:4445000][col].values\n",
    "            ax[n].fill_between(mean_df.index.values,\n",
    "                               mean_df.values-std, mean_df.values+std,\n",
    "                               facecolor='lightgreen',\n",
    "                               alpha = 0.5, label=col)\n",
    "            ax[n].legend()\n",
    "            n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del sample_submission\n",
    "del seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = pd.read_csv(\"LANL Earthquake Prediction/train.csv\",dtype={\"acoustic_data\": np.float32, \n",
    "                                                                       \"time_to_failure\": np.float32})\n",
    "float_data = float_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "     return np.c_[z.mean(axis=1), \n",
    "                  np.median(np.abs(z), axis=1),\n",
    "                  z.std(axis=1), \n",
    "                  z.max(axis=1),\n",
    "                  z.min(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:]),\n",
    "                 temp[:, -1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 16\n",
    "def generator(data, min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - 1\n",
    "    while True:\n",
    "        rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "         \n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            targets[j] = data[row, 1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_gen = generator(float_data, batch_size=batch_size)\n",
    "valid_gen = generator(float_data, batch_size=batch_size)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(\"model.hdf5\", monitor='val_loss', save_weights_only=False, verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNGRU(48, input_shape=(None, n_features)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpointer],\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "perf_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('LANL Earthquake Prediction/sample_submission.csv', index_col='seg_id', \n",
    "                         dtype={\"time_to_failure\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seg_id in enumerate(submission.index):\n",
    "    seg = pd.read_csv('LANL Earthquake Prediction/test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    submission.time_to_failure[i] = model.predict(np.expand_dims(create_X(x), 0))\n",
    "\n",
    "submission.head()\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
