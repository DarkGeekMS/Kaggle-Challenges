{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util.montage import montage2d as montage\n",
    "% matplotlib inline\n",
    "\n",
    "import gc; gc.enable()\n",
    "\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.morphology import binary_opening, disk\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import models, layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "\n",
    "ship_dir = 'data'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')\n",
    "test_image_dir = os.path.join(ship_dir, 'test')\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = None\n",
    "\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 600\n",
    "\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 150\n",
    "\n",
    "# whether to augment using brightness or not\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    \n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T \n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    \n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = pd.read_csv(os.path.join('data/','train_ship_segmentations_clean.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "rle_0 = masks.query('ImageId==\"00021ddc3.jpg\"')['EncodedPixels']\n",
    "img_0 = masks_as_image(rle_0)\n",
    "ax1.imshow(img_0[:, :, 0])\n",
    "ax1.set_title('Image$_0$')\n",
    "rle_1 = multi_rle_encode(img_0)\n",
    "img_1 = masks_as_image(rle_1)\n",
    "ax2.imshow(img_1[:, :, 0])\n",
    "ax2.set_title('Image$_1$')\n",
    "print('Check Decoding->Encoding',\n",
    "      'RLE_0:', len(rle_0), '->',\n",
    "      'RLE_1:', len(rle_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                               os.stat(os.path.join(train_image_dir, \n",
    "                                                                                    c_img_id)).st_size/1024)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] \n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ships'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+2)//3)\n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(lambda x: x.sample(1500))\n",
    "balanced_train_df['ships'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    \n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = make_image_gen(balanced_train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "batch_rgb = montage_rgb(train_x)\n",
    "batch_seg = montage(train_y[:, :, :, 0])\n",
    "ax1.imshow(batch_rgb)\n",
    "ax1.set_title('Images')\n",
    "ax2.imshow(batch_seg)\n",
    "ax2.set_title('Segmentations')\n",
    "ax3.imshow(mark_boundaries(batch_rgb, \n",
    "                           batch_seg.astype(int)))\n",
    "ax3.set_title('Outlined Ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "batch_rgb = montage_rgb(train_x)\n",
    "batch_seg = montage(train_y[:, :, :, 0])\n",
    "ax1.imshow(batch_rgb)\n",
    "ax1.set_title('Images')\n",
    "ax2.imshow(batch_seg)\n",
    "ax2.set_title('Segmentations')\n",
    "ax3.imshow(mark_boundaries(batch_rgb, \n",
    "                           batch_seg.astype(int)))\n",
    "ax3.set_title('Outlined Ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((768, 768, 3), name='img')\n",
    "\n",
    "c1 = Conv2D(4, (3, 3), activation='relu', padding='same') (input_img)\n",
    "a1 = MaxPooling2D((2, 2))(c1)\n",
    "c1 = Dropout(0.2)(c1)\n",
    "c1 = Conv2D(4, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "cat1 = concatenate([p1, a1])\n",
    "\n",
    "c2 = Conv2D(8, (3, 3), activation='relu', padding='same') (cat1)\n",
    "a2 = MaxPooling2D((2, 2))(c2)\n",
    "c2 = Dropout(0.2)(c2)\n",
    "c2 = Conv2D(8, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "cat2 = concatenate([p2, a2])\n",
    "\n",
    "c3 = Conv2D(16, (3, 3), activation='relu', padding='same') (cat2)\n",
    "a3 = MaxPooling2D((2, 2))(c3)\n",
    "c3 = Dropout(0.2)(c3)\n",
    "c3 = Conv2D(16, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "cat3 = concatenate([p3, a3])\n",
    "\n",
    "c4 = Conv2D(32, (3, 3), activation='relu', padding='same') (cat3)\n",
    "a4 = MaxPooling2D((2, 2))(c4)\n",
    "c4 = Dropout(0.2)(c4)\n",
    "c4 = Conv2D(32, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D((2, 2)) (c4)\n",
    "\n",
    "cat4 = concatenate([p4, a4])\n",
    "\n",
    "c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (cat4)\n",
    "a5 = MaxPooling2D((2, 2))(c5)\n",
    "c5 = Dropout(0.2)(c5)\n",
    "c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n",
    "p5 = MaxPooling2D((2, 2)) (c5)\n",
    "\n",
    "cat5 = concatenate([p5, a5])\n",
    "\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', padding='same') (cat5)\n",
    "c6 = Dropout(0.2)(c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c5])\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Dropout(0.2)(c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c4])\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Dropout(0.2)(c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c3])\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Dropout(0.2)(c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "u10 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c9)\n",
    "u10 = concatenate([u10, c2])\n",
    "c10 = Conv2D(8, (3, 3), activation='relu', padding='same') (u10)\n",
    "c10 = Dropout(0.2)(c10)\n",
    "c10 = Conv2D(8, (3, 3), activation='relu', padding='same') (c10)\n",
    "\n",
    "u11 = Conv2DTranspose(4, (2, 2), strides=(2, 2), padding='same') (c10)\n",
    "u11 = concatenate([u11, c1], axis = 3)\n",
    "c11 = Conv2D(4, (3, 3), activation='relu', padding='same') (u11)\n",
    "c11 = Dropout(0.2)(c11)\n",
    "c11 = Conv2D(4, (3, 3), activation='relu', padding='same') (c11)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c11)\n",
    "\n",
    "model = Model(inputs=[input_img], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer='adam', loss= weighted_bce_dice_loss, metrics=[mean_iou, 'accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"{}_best.hdf5\".format('model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=2, mode='min',min_lr=1e-6)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10, verbose=2) \n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "\n",
    "aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n",
    "\n",
    "results = model.fit_generator(aug_gen, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=100, \n",
    "                             validation_data=(valid_x, valid_y),\n",
    "                             callbacks=callbacks_list, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(valid_x)\n",
    "print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 10))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = model\n",
    "fullres_model.save('fullres_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullres_model = models.load_model('fullres_model.h5', compile=False)\n",
    "seg_in_shape = fullres_model.get_input_shape_at(0)[1:3]\n",
    "seg_out_shape = fullres_model.get_output_shape_at(0)[1:3]\n",
    "print(seg_in_shape, '->', seg_out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(8, 2, figsize = (10, 40))\n",
    "for (ax1, ax2), c_img_name in zip(m_axs, test_paths):\n",
    "    c_path = os.path.join(test_image_dir, c_img_name)\n",
    "    c_img = imread(c_path)\n",
    "    first_img = np.expand_dims(c_img, 0)/255.0\n",
    "    first_seg = fullres_model.predict(first_img)\n",
    "    ax1.imshow(first_img[0])\n",
    "    ax1.set_title('Image')\n",
    "    ax2.imshow(first_seg[0, :, :, 0], vmin = 0, vmax = 1)\n",
    "    ax2.set_title('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pred_rows = []\n",
    "for c_img_name in tqdm_notebook(test_paths):\n",
    "    c_path = os.path.join(test_image_dir, c_img_name)\n",
    "    c_img = imread(c_path)\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = fullres_model.predict(c_img)[0]\n",
    "    cur_seg = binary_opening(cur_seg>0.5, np.expand_dims(disk(2), -1))\n",
    "    cur_rles = multi_rle_encode(cur_seg)\n",
    "    if len(cur_rles)>0:\n",
    "        for c_rle in cur_rles:\n",
    "            out_pred_rows += [{'ImageId': c_img_name, 'EncodedPixels': c_rle}]\n",
    "    else:\n",
    "        out_pred_rows += [{'ImageId': c_img_name, 'EncodedPixels': None}]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(out_pred_rows)[['ImageId', 'EncodedPixels']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['counts'] = submission_df.apply(lambda c_row: c_row['counts'] if \n",
    "                                    isinstance(c_row['EncodedPixels'], str) else\n",
    "                                    0, 1)\n",
    "submission_df['counts'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
